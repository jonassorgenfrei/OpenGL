#version 430 core

layout (local_size_x = 1, local_size_y = 1) in;

// ----------------------------------------------------------------------------
//
// Uniforms
//
// ----------------------------------------------------------------------------

layout (binding = 0, r8) uniform image2D Src;                    /**< Quellbild */
layout (binding = 1, r8) uniform image2D Dst;                    /**< Zielbild */

layout (binding = 0) uniform sampler2D DepthBuffer;                 /**< Depth-Buffer der Szene */
layout (binding = 1) uniform sampler2D NormalBuffer;                /**< Buffer für die Normalen der Szene */

layout (location = 0) uniform ivec2 Direction;                      /**< Richtung, in die der Blur ausgeführt wird */
layout (location = 1) uniform mat4 InverseProjectionMatrix;         /**< Inverse Projektions-Matrix */

/**
 * Inverse Depth-Range Transformation
 *
 * @param depth                 Tiefe aus dem Depth-Buffer
 *
 * @return Tiefe im Clipping-Koordinatensystem
 */
float inverseDepthRangeTransformation(float depth) {
    return (2.0 * depth - gl_DepthRange.near - gl_DepthRange.far) /
            (gl_DepthRange.far - gl_DepthRange.near);
}


/**
 * @brief Gibt die Weltnormale an der Position invocationID in Screen-Space zurück.
 *
 * @param invocationID      Position im Screen-Space
 * @param size              Auflösung des Framebuffers
 *
 * @return Normale im Weltkoordinatensystem
 */
vec3 normalAt(uvec2 invocationID, vec2 size) {
    vec2 texCoord = 2*vec2(invocationID.xy) / size;
    return 2*texture(NormalBuffer, texCoord).rgb - vec3(1);
}

/**
 * @brief Gibt die Tiefe in Clipping-Koordinaten an der Position invocationID im Screen-Space zurück.
 *
 * @param invocationID      Position im Screen-Space
 * @param size              Auflösung des Framebuffers
 *
 * @return Tiefe im Clipping-Koordinatensystem
 */
float ndcDepthAt(uvec2 invocationID, vec2 size) {
    vec2 texCoord = vec2(2*vec2(invocationID.xy)) / size;

    return inverseDepthRangeTransformation(texture(DepthBuffer, texCoord).r);
}

/**
 * @brief Gibt die Position des Pixels im Betrachter-Koordinatensystem zurück
 *
 * @param invocationID      Position im Screen-Space
 * @param size              Auflösung des Framebuffers
 *
 * @return Position des Pixels im Betrachter-Koordinatensystem
 */
vec3 viewPositionAt(uvec2 invocationID, vec2 size) {
    float ndcDepth = ndcDepthAt(invocationID, size);

    vec2 texCoord = vec2(2*invocationID.xy) / size;
    vec4 ndcCoordinate = vec4(2*texCoord - vec2(1), ndcDepth, 1.0);
    vec4 viewCoordinate = InverseProjectionMatrix*ndcCoordinate;

    return viewCoordinate.xyz/viewCoordinate.w;
}

/**
 * Einsprungpunkt für den Compute Shader
 */
void main() {
    ivec2 position = ivec2(gl_GlobalInvocationID.xy);

    const int S = 3;
    int numSamples = 2*S + 1;

    ivec2 srcImageSize = imageSize(Src);
    vec2 size = textureSize(NormalBuffer, 0);

    vec3 centerNormal = normalAt(position, size);
    vec3 centerViewPosition = viewPositionAt(position, size);

    int stride = 1;

    float value = 0;
    float weight = 0;

    for (int i = -S; i <= S; ++i) {
        ivec2 samplePosition = max(ivec2(0), min(ivec2(srcImageSize-1), position + i*stride*Direction));

        vec3 sampleNormal = normalAt(samplePosition, size);
        vec3 sampleViewPosition = viewPositionAt(samplePosition, size);

        float normalWeight = max(0, min(1, dot(centerNormal, sampleNormal)));
        float depthWeight = 1 - smoothstep(0.0, 0.2, length(centerViewPosition - sampleViewPosition));

        float ao = imageLoad(Src, samplePosition).r;

        float sampleWeight = min(depthWeight, normalWeight);

        value += sampleWeight*ao;
        weight += sampleWeight;
    }

    vec4 color = vec4(vec3(value / weight), 0);
    imageStore(Dst, position, color);
}
